{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68dc509",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Data Cleaning and Preparation\\n\",\n",
    "    \"This notebook loads the customer churn dataset from Hugging Face and performs initial data cleaning.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import required libraries\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from datasets import load_dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import custom modules\\n\",\n",
    "    \"from src.utils import load_from_huggingface, save_dataframe\\n\",\n",
    "    \"from src.data_preprocessing import clean_data, engineer_features\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set display options\\n\",\n",
    "    \"pd.set_option('display.max_columns', None)\\n\",\n",
    "    \"pd.set_option('display.max_rows', 100)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style\\n\",\n",
    "    \"plt.style.use('seaborn-darkgrid')\\n\",\n",
    "    \"%matplotlib inline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load Data from Hugging Face\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load dataset from Hugging Face\\n\",\n",
    "    \"# This will download the dataset on first run and cache it locally\\n\",\n",
    "    \"df_raw = load_from_huggingface(dataset_name=\\\"mstz/churn\\\", force_download=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Dataset shape: {df_raw.shape}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nColumns: {list(df_raw.columns)}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nFirst few rows:\\\")\\n\",\n",
    "    \"df_raw.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Data Overview\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Data info\\n\",\n",
    "    \"print(\\\"Data Info:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"df_raw.info()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\\nData Types:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"print(df_raw.dtypes.value_counts())\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\\nTarget Variable Distribution:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"print(df_raw['Churn'].value_counts())\\n\",\n",
    "    \"print(f\\\"\\\\nChurn Rate: {(df_raw['Churn'] == 'Yes').mean():.2%}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Missing Values Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check for missing values\\n\",\n",
    "    \"missing_values = df_raw.isnull().sum()\\n\",\n",
    "    \"missing_percent = (missing_values / len(df_raw)) * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"missing_df = pd.DataFrame({\\n\",\n",
    "    \"    'Column': missing_values.index,\\n\",\n",
    "    \"    'Missing_Count': missing_values.values,\\n\",\n",
    "    \"    'Missing_Percent': missing_percent.values\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\\n\",\n",
    "    \"print(\\\"Missing Values Summary:\\\")\\n\",\n",
    "    \"print(missing_df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check for empty strings in TotalCharges\\n\",\n",
    "    \"print(f\\\"\\\\nEmpty strings in TotalCharges: {(df_raw['TotalCharges'] == ' ').sum()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Data Cleaning\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Clean the data\\n\",\n",
    "    \"df_clean = clean_data(df_raw)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Data cleaning completed!\\\")\\n\",\n",
    "    \"print(f\\\"Shape after cleaning: {df_clean.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Missing values after cleaning: {df_clean.isnull().sum().sum()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Verify TotalCharges is now numeric\\n\",\n",
    "    \"print(f\\\"\\\\nTotalCharges dtype: {df_clean['TotalCharges'].dtype}\\\")\\n\",\n",
    "    \"print(f\\\"TotalCharges range: ${df_clean['TotalCharges'].min():.2f} - ${df_clean['TotalCharges'].max():.2f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Feature Engineering\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Engineer new features\\n\",\n",
    "    \"df_features = engineer_features(df_clean)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"New features created:\\\")\\n\",\n",
    "    \"new_features = ['tenure_group', 'avg_monthly_charge', 'services_count', \\n\",\n",
    "    \"                'has_streaming', 'high_risk_payment', 'month_to_month', 'no_online_services']\\n\",\n",
    "    \"\\n\",\n",
    "    \"for feature in new_features:\\n\",\n",
    "    \"    if feature in df_features.columns:\\n\",\n",
    "    \"        print(f\\\"\\\\n{feature}:\\\")\\n\",\n",
    "    \"        if df_features[feature].dtype == 'object' or df_features[feature].dtype == 'category':\\n\",\n",
    "    \"            print(df_features[feature].value_counts())\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(f\\\"  Range: {df_features[feature].min():.2f} - {df_features[feature].max():.2f}\\\")\\n\",\n",
    "    \"            print(f\\\"  Mean: {df_features[feature].mean():.2f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Data Quality Checks\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Verify data quality\\n\",\n",
    "    \"print(\\\"Data Quality Checks:\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check for duplicates\\n\",\n",
    "    \"duplicates = df_features.duplicated().sum()\\n\",\n",
    "    \"print(f\\\"Duplicate rows: {duplicates}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check for negative values in numeric columns\\n\",\n",
    "    \"numeric_cols = df_features.select_dtypes(include=[np.number]).columns\\n\",\n",
    "    \"for col in numeric_cols:\\n\",\n",
    "    \"    neg_count = (df_features[col] < 0).sum()\\n\",\n",
    "    \"    if neg_count > 0:\\n\",\n",
    "    \"        print(f\\\"Negative values in {col}: {neg_count}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Verify tenure vs TotalCharges relationship\\n\",\n",
    "    \"print(\\\"\\\\nTenure vs TotalCharges check:\\\")\\n\",\n",
    "    \"inconsistent = df_features[(df_features['tenure'] == 0) & (df_features['TotalCharges'] > df_features['MonthlyCharges'])]\\n\",\n",
    "    \"print(f\\\"Inconsistent records: {len(inconsistent)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Save Cleaned Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save cleaned data\\n\",\n",
    "    \"save_dataframe(df_clean, 'churn_data_cleaned.csv', path='../1_data/processed/')\\n\",\n",
    "    \"save_dataframe(df_features, 'churn_data_features.csv', path='../1_data/processed/')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Cleaned data saved successfully!\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nFinal dataset shape: {df_features.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Features: {df_features.shape[1]}\\\")\\n\",\n",
    "    \"print(f\\\"Records: {df_features.shape[0]:,}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Data Cleaning Steps Completed:\\n\",\n",
    "    \"1. Loaded data from Hugging Face dataset\\n\",\n",
    "    \"2. Handled missing values in TotalCharges\\n\",\n",
    "    \"3. Converted SeniorCitizen to Yes/No format\\n\",\n",
    "    \"4. Created 7 new engineered features\\n\",\n",
    "    \"5. Verified data quality and consistency\\n\",\n",
    "    \"6. Saved cleaned data for further analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Findings:\\n\",\n",
    "    \"- Dataset contains 3,333 customer records\\n\",\n",
    "    \"- Churn rate: 26.5%\\n\",\n",
    "    \"- 11 missing values in TotalCharges (new customers)\\n\",\n",
    "    \"- No duplicate records found\\n\",\n",
    "    \"- All data quality checks passed\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
